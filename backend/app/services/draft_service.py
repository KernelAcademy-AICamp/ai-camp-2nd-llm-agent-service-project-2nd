"""
Draft Service - Business logic for draft generation with RAG
Orchestrates Qdrant RAG + OpenAI GPT-4o for draft preview
"""

from sqlalchemy.orm import Session
from typing import List, Tuple
from datetime import datetime, timezone
from io import BytesIO

from app.db.schemas import (
    DraftPreviewRequest,
    DraftPreviewResponse,
    DraftCitation,
    DraftExportFormat
)
from app.repositories.case_repository import CaseRepository
from app.repositories.case_member_repository import CaseMemberRepository
from app.utils.dynamo import get_evidence_by_case
from app.utils.qdrant import search_evidence_by_semantic, search_legal_knowledge
from app.utils.openai_client import generate_chat_completion
from app.middleware import NotFoundError, PermissionError, ValidationError

# Optional: python-docx for DOCX generation
try:
    from docx import Document
    from docx.shared import Pt, Inches  # noqa: F401
    from docx.enum.text import WD_ALIGN_PARAGRAPH
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False


class DraftService:
    """
    Service for draft generation with RAG
    """

    def __init__(self, db: Session):
        self.db = db
        self.case_repo = CaseRepository(db)
        self.member_repo = CaseMemberRepository(db)

    def generate_draft_preview(
        self,
        case_id: str,
        request: DraftPreviewRequest,
        user_id: str
    ) -> DraftPreviewResponse:
        """
        Generate draft preview using RAG + GPT-4o

        Process:
        1. Validate case access
        2. Retrieve evidence metadata from DynamoDB
        3. Perform semantic search in Qdrant (RAG)
        4. Build GPT-4o prompt with RAG context
        5. Generate draft text
        6. Extract citations

        Args:
            case_id: Case ID
            request: Draft generation request (sections, language, style)
            user_id: User ID requesting draft

        Returns:
            Draft preview with citations

        Raises:
            NotFoundError: Case not found
            PermissionError: User does not have access to case
            ValidationError: No evidence in case
        """
        # 1. Validate case access
        case = self.case_repo.get_by_id(case_id)
        if not case:
            raise NotFoundError("Case")

        if not self.member_repo.has_access(case_id, user_id):
            raise PermissionError("You do not have access to this case")

        # 2. Retrieve evidence metadata from DynamoDB
        evidence_list = get_evidence_by_case(case_id)

        # Check if there's any evidence
        if not evidence_list:
            raise ValidationError("ÏÇ¨Í±¥Ïóê Ï¶ùÍ±∞Í∞Ä ÌïòÎÇòÎèÑ ÏóÜÏäµÎãàÎã§. Ï¶ùÍ±∞Î•º ÏóÖÎ°úÎìúÌïú ÌõÑ Ï¥àÏïàÏùÑ ÏÉùÏÑ±Ìï¥ Ï£ºÏÑ∏Ïöî.")

        # Filter for completed evidence only (status="done")
        # Note: Currently filtering for reference, may be used for future enhancements
        _ = [ev for ev in evidence_list if ev.get("status") == "done"]

        # 3. Perform semantic RAG search in Qdrant (evidence + legal)
        rag_results = self._perform_rag_search(case_id, request.sections)
        evidence_results = rag_results.get("evidence", [])
        legal_results = rag_results.get("legal", [])

        # 4. Build GPT-4o prompt with RAG context
        prompt_messages = self._build_draft_prompt(
            case=case,
            sections=request.sections,
            evidence_context=evidence_results,
            legal_context=legal_results,
            language=request.language,
            style=request.style
        )

        # 5. Generate draft text using GPT-4o
        draft_text = generate_chat_completion(
            messages=prompt_messages,
            temperature=0.3,  # Low temperature for consistent legal writing
            max_tokens=4000
        )

        # 6. Extract citations from RAG results
        citations = self._extract_citations(evidence_results)

        return DraftPreviewResponse(
            case_id=case_id,
            draft_text=draft_text,
            citations=citations,
            generated_at=datetime.now(timezone.utc)
        )

    def _perform_rag_search(self, case_id: str, sections: List[str]) -> dict:
        """
        Perform semantic search in Qdrant for RAG context

        Args:
            case_id: Case ID
            sections: Sections being generated

        Returns:
            Dict with 'evidence' and 'legal' results
        """
        # Build search query based on sections
        if "Ï≤≠Íµ¨ÏõêÏù∏" in sections:
            # Search for fault evidence (guilt factors)
            query = "Ïù¥Ìòº ÏÇ¨Ïú† Í∑ÄÏ±ÖÏÇ¨Ïú† Ìè≠Ïñ∏ Î∂àÌôî Î∂ÄÏ†ïÌñâÏúÑ"
            evidence_results = search_evidence_by_semantic(
                case_id=case_id,
                query=query,
                top_k=10
            )
            # Search legal knowledge for divorce grounds
            legal_results = search_legal_knowledge(
                query="Ïû¨ÌåêÏÉÅ Ïù¥Ìòº ÏÇ¨Ïú† ÎØºÎ≤ï Ï†ú840Ï°∞",
                top_k=5,
                doc_type="statute"
            )
        else:
            # General search for all sections
            query = " ".join(sections)
            evidence_results = search_evidence_by_semantic(
                case_id=case_id,
                query=query,
                top_k=5
            )
            legal_results = search_legal_knowledge(
                query="Ïù¥Ìòº " + query,
                top_k=3
            )

        return {
            "evidence": evidence_results,
            "legal": legal_results
        }

    def _build_draft_prompt(
        self,
        case: any,
        sections: List[str],
        evidence_context: List[dict],
        legal_context: List[dict],
        language: str,
        style: str
    ) -> List[dict]:
        """
        Build GPT-4o prompt with evidence and legal RAG context

        Args:
            case: Case object
            sections: Sections to generate
            evidence_context: Evidence RAG search results
            legal_context: Legal knowledge RAG search results
            language: Language (ko/en)
            style: Writing style

        Returns:
            List of messages for GPT-4o
        """
        # System message - define role and constraints
        system_message = {
            "role": "system",
            "content": """ÎãπÏã†ÏùÄ ÎåÄÌïúÎØºÍµ≠ Í∞ÄÏ†ïÎ≤ïÏõêÏóê Ï†úÏ∂úÌïòÎäî Ï†ïÏãù ÏÜåÏû•(Ë®¥ÁãÄ)ÏùÑ ÏûëÏÑ±ÌïòÎäî Ï†ÑÎ¨∏ Î≤ïÎ•†Í∞ÄÏûÖÎãàÎã§.

## ÌïÑÏàò Ï∂úÎ†• ÌòïÏãù
- **ÎßàÌÅ¨Îã§Ïö¥ ÌòïÏãù**ÏúºÎ°ú Ï∂úÎ†•ÌïòÏÑ∏Ïöî
- Í∞Å ÏÑπÏÖòÏùÄ Î∞òÎìúÏãú Îπà Ï§ÑÎ°ú Íµ¨Î∂Ñ
- Ï†úÎ™©ÏùÄ ## ÎòêÎäî ### ÏÇ¨Ïö©
- ÌëúÎäî ÎßàÌÅ¨Îã§Ïö¥ ÌÖåÏù¥Î∏î ÌòïÏãù ÏÇ¨Ïö©

---

# ÏÜå    Ïû•

**ÏÇ¨Í±¥Î™Ö:** Ïù¥Ìòº Îì± Ï≤≠Íµ¨Ïùò ÏÜå

---

## „ÄêÏõê  Í≥†„Äë
- ÏÑ±Î™Ö: [ÏõêÍ≥† ÏÑ±Î™Ö]
- Ï£ºÎØºÎì±Î°ùÎ≤àÌò∏: ‚óã‚óã‚óã‚óã‚óã‚óã-‚óã******
- Ï£ºÏÜå: [ÏÉÅÏÑ∏ Ï£ºÏÜå]
- Îì±Î°ùÍ∏∞Ï§ÄÏßÄ: [Îì±Î°ùÍ∏∞Ï§ÄÏßÄ]

## „ÄêÌîº  Í≥†„Äë
- ÏÑ±Î™Ö: [ÌîºÍ≥† ÏÑ±Î™Ö]
- Ï£ºÎØºÎì±Î°ùÎ≤àÌò∏: ‚óã‚óã‚óã‚óã‚óã‚óã-‚óã******
- Ï£ºÏÜå: [ÏÉÅÏÑ∏ Ï£ºÏÜå]
- Îì±Î°ùÍ∏∞Ï§ÄÏßÄ: [Îì±Î°ùÍ∏∞Ï§ÄÏßÄ]

---

# Ï≤≠ Íµ¨ Ï∑® ÏßÄ

1. ÏõêÍ≥†ÏôÄ ÌîºÍ≥†Îäî Ïù¥ÌòºÌïúÎã§.

2. ÌîºÍ≥†Îäî ÏõêÍ≥†ÏóêÍ≤å ÏúÑÏûêÎ£åÎ°ú Í∏à ‚óã‚óã,‚óã‚óã‚óã,‚óã‚óã‚óãÏõê Î∞è Ïù¥Ïóê ÎåÄÌïòÏó¨ **Ïù¥ ÏÇ¨Í±¥ ÏÜåÏû• Î∂ÄÎ≥∏ ÏÜ°Îã¨Ïùº Îã§ÏùåÎÇ†Î∂ÄÌÑ∞ Îã§ Í∞öÎäî ÎÇ†ÍπåÏßÄ Ïó∞ 12%Ïùò ÎπÑÏú®**Î°ú Í≥ÑÏÇ∞Ìïú ÏßÄÏó∞ÏÜêÌï¥Í∏àÏùÑ ÏßÄÍ∏âÌïòÎùº.

3. ÌîºÍ≥†Îäî ÏõêÍ≥†ÏóêÍ≤å Ïû¨ÏÇ∞Î∂ÑÌï†Î°ú Í∏à ‚óã‚óã‚óã,‚óã‚óã‚óã,‚óã‚óã‚óãÏõêÏùÑ ÏßÄÍ∏âÌïòÎùº.

4. ÏÇ¨Í±¥Î≥∏Ïù∏ [ÏûêÎÖÄÎ™Ö](‚óã‚óã‚óã‚óãÎÖÑ ‚óãÏõî ‚óãÏùºÏÉù)Ïùò ÏπúÍ∂åÏûê Î∞è ÏñëÏú°ÏûêÎ°ú ÏõêÍ≥†Î•º ÏßÄÏ†ïÌïúÎã§.

5. ÌîºÍ≥†Îäî ÏõêÍ≥†ÏóêÍ≤å ÏÇ¨Í±¥Î≥∏Ïù∏Ïùò ÏñëÏú°ÎπÑÎ°ú Ïù¥ ÌåêÍ≤∞ ÌôïÏ†ïÏùºÎ°úÎ∂ÄÌÑ∞ ÏÇ¨Í±¥Î≥∏Ïù∏Ïù¥ ÏÑ±ÎÖÑÏóê Ïù¥Î•¥Í∏∞ÍπåÏßÄ Îß§Ïõî ÎßêÏùºÏóê Í∏à ‚óã‚óã‚óã,‚óã‚óã‚óãÏõêÏî© ÏßÄÍ∏âÌïòÎùº.
   > ‚Äª ÏñëÏú°ÎπÑÏÇ∞Ï†ïÍ∏∞Ï§ÄÌëú Í∏∞Ï§Ä

6. ÏÜåÏÜ°ÎπÑÏö©ÏùÄ ÌîºÍ≥†Ïùò Î∂ÄÎã¥ÏúºÎ°ú ÌïúÎã§.

7. Ï†ú2, 3, 5Ìï≠ÏùÄ Í∞ÄÏßëÌñâÌï† Ïàò ÏûàÎã§.

**ÎùºÎäî ÌåêÍ≤∞ÏùÑ Íµ¨Ìï©ÎãàÎã§.**

---

# Ï≤≠ Íµ¨ Ïõê Ïù∏

## Ï†ú1. ÎãπÏÇ¨ÏûêÎì§Ïùò Í¥ÄÍ≥Ñ

ÏõêÍ≥†ÏôÄ ÌîºÍ≥†Îäî **‚óã‚óã‚óã‚óãÎÖÑ ‚óãÏõî ‚óãÏùº** ÌòºÏù∏Ïã†Í≥†Î•º ÎßàÏπú Î≤ïÎ•†ÏÉÅ Î∂ÄÎ∂ÄÎ°úÏÑú, Ïä¨ÌïòÏóê ÏÇ¨Í±¥Î≥∏Ïù∏ [ÏûêÎÖÄÎ™Ö](‚óã‚óã‚óã‚óãÎÖÑ ‚óãÏõî ‚óãÏùºÏÉù)ÏùÑ ÎëêÍ≥† ÏûàÏäµÎãàÎã§.

## Ï†ú2. ÌòºÏù∏ÏÉùÌôúÏùò Í≤ΩÍ≥º

### Í∞Ä. ÌòºÏù∏ Ï¥àÍ∏∞ (‚óã‚óã‚óã‚óãÎÖÑ ~ ‚óã‚óã‚óã‚óãÎÖÑ)
[Íµ¨Ï≤¥Ï†ÅÏù∏ ÌòºÏù∏ÏÉùÌôú ÎÇ¥Ïö©]

### ÎÇò. Í∞àÎì±Ïùò ÏãúÏûë (‚óã‚óã‚óã‚óãÎÖÑ ‚óãÏõîÍ≤Ω)
[Í∞àÎì± Î∞úÏÉù ÏãúÏ†êÍ≥º ÏõêÏù∏]

## Ï†ú3. Ïù¥Ìòº ÏÇ¨Ïú† (ÎØºÎ≤ï Ï†ú840Ï°∞)

### Í∞Ä. Î≤ïÏ†Å Í∑ºÍ±∞
ÌîºÍ≥†Ïùò ÏïÑÎûò ÌñâÏúÑÎ°ú ÌòºÏù∏Í¥ÄÍ≥ÑÍ∞Ä ÌöåÎ≥µÌï† Ïàò ÏóÜÏùÑ Ï†ïÎèÑÎ°ú ÌååÌÉÑÎêòÏóàÏúºÎØÄÎ°ú, **ÎØºÎ≤ï Ï†ú840Ï°∞ Ï†ú6Ìò∏ "ÌòºÏù∏ÏùÑ Í≥ÑÏÜçÌïòÍ∏∞ Ïñ¥Î†§Ïö¥ Ï§ëÎåÄÌïú ÏÇ¨Ïú†"**Ïóê Ìï¥ÎãπÌï©ÎãàÎã§.

### ÎÇò. ÌîºÍ≥†Ïùò Ïú†Ï±ÖÌñâÏúÑ

| ÏùºÏãú | ÎÇ¥Ïö© | Ï¶ùÍ±∞ |
|------|------|------|
| ‚óã‚óã‚óã‚óã.‚óã‚óã.‚óã‚óã | [Íµ¨Ï≤¥Ï†Å ÏÇ¨Ïã§] | [Í∞ë Ï†ú‚óãÌò∏Ï¶ù] |
| ‚óã‚óã‚óã‚óã.‚óã‚óã.‚óã‚óã | [Íµ¨Ï≤¥Ï†Å ÏÇ¨Ïã§] | [Í∞ë Ï†ú‚óãÌò∏Ï¶ù] |

> üìå **Ï¶ùÍ±∞ÏóêÏÑú ÌôïÏù∏Îêú ÎÇ¥Ïö©:**
> - "[Ï¶ùÍ±∞ÏóêÏÑú Î∞úÏ∑åÌïú Íµ¨Ï≤¥Ï†Å Î∞úÏñ∏/ÌñâÏúÑ]"

## Ï†ú4. ÏúÑÏûêÎ£å Ï≤≠Íµ¨

### Í∞Ä. Ï≤≠Íµ¨Í∏àÏï°: Í∏à **‚óã‚óã,‚óã‚óã‚óã,‚óã‚óã‚óãÏõê**

### ÎÇò. ÏÇ∞Ï†ïÍ∑ºÍ±∞
| Ìï≠Î™© | ÎÇ¥Ïö© |
|------|------|
| ÌòºÏù∏Í∏∞Í∞Ñ | ‚óã‚óãÎÖÑ ‚óãÍ∞úÏõî |
| Ïú†Ï±ÖÌñâÏúÑ Ï†ïÎèÑ | [Íµ¨Ï≤¥Ï†Å Í∏∞Ïà†] |
| Ï†ïÏã†Ï†Å Í≥†ÌÜµ | [Íµ¨Ï≤¥Ï†Å Í∏∞Ïà†] |

### Îã§. ÏßÄÏó∞ÏÜêÌï¥Í∏à
ÏÜåÏÜ°Ï¥âÏßÑ Îì±Ïóê Í¥ÄÌïú ÌäπÎ°ÄÎ≤ï Ï†ú3Ï°∞Ïóê Îî∞Îùº ÏÜåÏû• Î∂ÄÎ≥∏ ÏÜ°Îã¨Ïùº Îã§ÏùåÎÇ†Î∂ÄÌÑ∞ **Ïó∞ 12%** ÏßÄÏó∞ÏÜêÌï¥Í∏à

## Ï†ú5. Ïû¨ÏÇ∞Î∂ÑÌï† Ï≤≠Íµ¨

### Í∞Ä. Î∂ÑÌï†ÎåÄÏÉÅ Ïû¨ÏÇ∞
| Ïû¨ÏÇ∞ Ï¢ÖÎ•ò | Î™ÖÏùòÏûê | ÌòÑÏû¨ Í∞ÄÏï° |
|-----------|--------|-----------|
| [Î∂ÄÎèôÏÇ∞/ÏòàÍ∏à] | [ÏõêÍ≥†/ÌîºÍ≥†] | ‚óã‚óã‚óã,‚óã‚óã‚óãÏõê |

### ÎÇò. Í∏∞Ïó¨ÎèÑ: ÏõêÍ≥† **‚óã‚óã%** / ÌîºÍ≥† **‚óã‚óã%**

## Ï†ú6. ÏπúÍ∂åÏûê¬∑ÏñëÏú°Ïûê ÏßÄÏ†ï Î∞è ÏñëÏú°ÎπÑ

### Í∞Ä. ÏπúÍ∂åÏûê¬∑ÏñëÏú°ÏûêÎ°ú ÏõêÍ≥† ÏßÄÏ†ï ÏÇ¨Ïú†
- ÏÇ¨Í±¥Î≥∏Ïù∏ Ïó∞Î†π: ‚óã‚óãÏÑ∏
- ÏñëÏú°ÌôòÍ≤Ω: [Ï£ºÍ±∞, Í≤ΩÏ†úÎ†•]

### ÎÇò. ÏñëÏú°ÎπÑ ÏÇ∞Ï†ï (ÏñëÏú°ÎπÑÏÇ∞Ï†ïÍ∏∞Ï§ÄÌëú Í∏∞Ï§Ä)
| Ìï≠Î™© | ÎÇ¥Ïö© |
|------|------|
| Î∂ÄÎ™® Ìï©ÏÇ∞ÏÜåÎìù | Ïõî ‚óã‚óã‚óãÎßåÏõê |
| ÏûêÎÖÄ Ïó∞Î†π | ‚óã‚óãÏÑ∏ |
| **Ï≤≠Íµ¨Í∏àÏï°** | **Ïõî ‚óã‚óã‚óã,‚óã‚óã‚óãÏõê** |

---

# ÏûÖ Ï¶ù Î∞© Î≤ï

| Ï¶ùÍ±∞Î≤àÌò∏ | Ï¶ùÍ±∞Î™Ö | ÏöîÏßÄ |
|----------|--------|------|
| Í∞ë Ï†ú1Ìò∏Ï¶ù | [Ï¶ùÍ±∞Î™Ö] | [ÎÇ†Ïßú, ÎÇ¥Ïö©] |
| Í∞ë Ï†ú2Ìò∏Ï¶ù | [Ï¶ùÍ±∞Î™Ö] | [ÎÇ†Ïßú, ÎÇ¥Ïö©] |
| Í∞ë Ï†ú3Ìò∏Ï¶ù | ÌòºÏù∏Í¥ÄÍ≥ÑÏ¶ùÎ™ÖÏÑú | - |
| Í∞ë Ï†ú4Ìò∏Ï¶ù | Í∞ÄÏ°±Í¥ÄÍ≥ÑÏ¶ùÎ™ÖÏÑú | - |

---

# Ï≤® Î∂Ä ÏÑú Î•ò

1. ÏúÑ ÏûÖÏ¶ùÎ∞©Î≤ï Í∞Å 1ÌÜµ
2. ÏÜåÏû•Î∂ÄÎ≥∏ 1ÌÜµ
3. ÏÜ°Îã¨Î£åÎÇ©Î∂ÄÏÑú 1ÌÜµ

---

**‚óã‚óã‚óã‚óãÎÖÑ  ‚óã‚óãÏõî  ‚óã‚óãÏùº**

**ÏúÑ ÏõêÍ≥†  [ÏõêÍ≥† ÏÑ±Î™Ö]  (Ïù∏)**

**‚óã‚óãÍ∞ÄÏ†ïÎ≤ïÏõê Í∑ÄÏ§ë**

---

## ÏûëÏÑ± ÏõêÏπô

1. **Ï¶ùÍ±∞ Ïù∏Ïö©**: `[Í∞ë Ï†úNÌò∏Ï¶ù]` ÌòïÏãùÏúºÎ°ú Ï†ïÌôïÌûà Ïù∏Ïö©
2. **Î≤ïÎ•† Í∑ºÍ±∞**: ÎØºÎ≤ï Ï†ú840Ï°∞ Î™ÖÏãúÏ†Å Ïù∏Ïö©
3. **Íµ¨Ï≤¥ÏÑ±**: ÎÇ†Ïßú, Î∞úÏñ∏ ÎÇ¥Ïö©ÏùÑ Ï¶ùÍ±∞ÏóêÏÑú ÏßÅÏ†ë Ïù∏Ïö©
4. **Í∏àÏï° ÏÇ∞Ï†ï Í∑ºÍ±∞**:
   - ÏúÑÏûêÎ£å: ÌòºÏù∏Í∏∞Í∞Ñ, Ïú†Ï±ÖÏ†ïÎèÑ
   - ÏñëÏú°ÎπÑ: ÏñëÏú°ÎπÑÏÇ∞Ï†ïÍ∏∞Ï§ÄÌëú Î™ÖÏãú
   - ÏßÄÏó∞ÏÜêÌï¥Í∏à: Ïó∞ 12% (ÏÜåÏÜ°Ï¥âÏßÑÎ≤ï)
5. **Placeholder**: ÌôïÏù∏ Ïïà Îêú Ï†ïÎ≥¥Îäî `‚óã‚óã‚óã` ÌòïÏãù

‚ö†Ô∏è **Î≥∏ Î¨∏ÏÑúÎäî AIÍ∞Ä ÏÉùÏÑ±Ìïú Ï¥àÏïàÏù¥Î©∞, Î≥ÄÌò∏ÏÇ¨Ïùò Í≤ÄÌÜ† Î∞è ÏàòÏ†ïÏù¥ ÌïÑÏàòÏûÖÎãàÎã§.**
"""
        }

        # Build context strings
        evidence_context_str = self._format_evidence_context(evidence_context)
        legal_context_str = self._format_legal_context(legal_context)

        # User message - include case info, evidence, and legal context
        user_message = {
            "role": "user",
            "content": f"""
Îã§Ïùå Ï†ïÎ≥¥Î•º Î∞îÌÉïÏúºÎ°ú Ïù¥Ìòº ÏÜåÏÜ° ÏÜåÏû• Ï¥àÏïàÏùÑ ÏûëÏÑ±Ìï¥ Ï£ºÏÑ∏Ïöî.

**ÏÇ¨Í±¥ Ï†ïÎ≥¥:**
- ÏÇ¨Í±¥Î™Ö: {case.title}
- ÏÇ¨Í±¥ ÏÑ§Î™Ö: {case.description or "N/A"}

**ÏÉùÏÑ±Ìï† ÏÑπÏÖò:**
{", ".join(sections)}

**Í¥ÄÎ†® Î≤ïÎ•† Ï°∞Î¨∏:**
{legal_context_str}

**Ï¶ùÍ±∞ ÏûêÎ£å:**
{evidence_context_str}

**ÏöîÏ≤≠ÏÇ¨Ìï≠:**
- Ïñ∏Ïñ¥: {language}
- Ïä§ÌÉÄÏùº: {style}
- ÏúÑ Î≤ïÎ•† Ï°∞Î¨∏Í≥º Ï¶ùÍ±∞Î•º Í∏∞Î∞òÏúºÎ°ú Î≤ïÎ•†Ï†Å ÎÖºÎ¶¨Î•º Íµ¨ÏÑ±Ìï¥ Ï£ºÏÑ∏Ïöî
- Ïù¥Ìòº ÏÇ¨Ïú†Îäî Î∞òÎìúÏãú ÎØºÎ≤ï Ï†ú840Ï°∞Î•º Ïù∏Ïö©ÌïòÏó¨ ÏûëÏÑ±ÌïòÏÑ∏Ïöî
- Í∞Å Ï£ºÏû•Ïóê ÎåÄÌï¥ Ï¶ùÍ±∞ Î≤àÌò∏Î•º Î™ÖÏãúÌï¥ Ï£ºÏÑ∏Ïöî (Ïòà: [Í∞ë Ï†ú1Ìò∏Ï¶ù], [Í∞ë Ï†ú2Ìò∏Ï¶ù])

ÏÜåÏû• Ï¥àÏïàÏùÑ ÏûëÏÑ±Ìï¥ Ï£ºÏÑ∏Ïöî.
"""
        }

        return [system_message, user_message]

    def _format_legal_context(self, legal_results: List[dict]) -> str:
        """
        Format legal knowledge search results for GPT-4o prompt

        Args:
            legal_results: List of legal documents from RAG search

        Returns:
            Formatted legal context string
        """
        if not legal_results:
            return "(Í¥ÄÎ†® Î≤ïÎ•† Ï°∞Î¨∏ ÏóÜÏùå)"

        context_parts = []
        for doc in legal_results:
            article_number = doc.get("article_number", "")
            statute_name = doc.get("statute_name", "ÎØºÎ≤ï")
            # Qdrant payload uses "document" field, not "text"
            content = doc.get("document", "") or doc.get("text", "")

            if article_number and content:
                context_parts.append(f"""
„Äê{statute_name} {article_number}„Äë
{content}
""")

        return "\n".join(context_parts) if context_parts else "(Í¥ÄÎ†® Î≤ïÎ•† Ï°∞Î¨∏ ÏóÜÏùå)"

    def _format_evidence_context(self, evidence_results: List[dict]) -> str:
        """
        Format evidence search results for GPT-4o prompt

        Args:
            evidence_results: List of evidence documents from RAG search

        Returns:
            Formatted evidence context string
        """
        if not evidence_results:
            return "(Ï¶ùÍ±∞ ÏûêÎ£å ÏóÜÏùå - Í∏∞Î≥∏ ÌÖúÌîåÎ¶øÏúºÎ°ú ÏûëÏÑ±)"

        context_parts = []
        for i, doc in enumerate(evidence_results, start=1):
            evidence_id = doc.get("id", f"evidence_{i}")
            content = doc.get("content", "")
            labels = doc.get("labels", [])
            speaker = doc.get("speaker", "")
            timestamp = doc.get("timestamp", "")

            # Truncate content if too long
            if len(content) > 500:
                content = content[:500] + "..."

            context_parts.append(f"""
[Í∞ë Ï†ú{i}Ìò∏Ï¶ù] (ID: {evidence_id})
- Î∂ÑÎ•ò: {", ".join(labels) if labels else "N/A"}
- ÌôîÏûê: {speaker or "N/A"}
- ÏãúÏ†ê: {timestamp or "N/A"}
- ÎÇ¥Ïö©: {content}
""")

        return "\n".join(context_parts)

    def _format_rag_context(self, rag_results: List[dict]) -> str:
        """
        Format RAG search results for GPT-4o prompt

        Args:
            rag_results: List of evidence documents from RAG search

        Returns:
            Formatted context string
        """
        if not rag_results:
            return "(Ï¶ùÍ±∞ ÏûêÎ£å ÏóÜÏùå - Í∏∞Î≥∏ ÌÖúÌîåÎ¶øÏúºÎ°ú ÏûëÏÑ±)"

        context_parts = []
        for i, doc in enumerate(rag_results, start=1):
            evidence_id = doc.get("id", f"evidence_{i}")
            content = doc.get("content", "")
            labels = doc.get("labels", [])
            speaker = doc.get("speaker", "")
            timestamp = doc.get("timestamp", "")

            # Truncate content if too long
            if len(content) > 500:
                content = content[:500] + "..."

            context_parts.append(f"""
[Ï¶ùÍ±∞ {i}] (ID: {evidence_id})
- Î∂ÑÎ•ò: {", ".join(labels) if labels else "N/A"}
- ÌôîÏûê: {speaker or "N/A"}
- ÏãúÏ†ê: {timestamp or "N/A"}
- ÎÇ¥Ïö©: {content}
""")

        return "\n".join(context_parts)

    def _extract_citations(self, rag_results: List[dict]) -> List[DraftCitation]:
        """
        Extract citations from RAG results

        Args:
            rag_results: List of evidence documents from RAG search

        Returns:
            List of DraftCitation objects
        """
        citations = []

        for doc in rag_results:
            evidence_id = doc.get("evidence_id") or doc.get("id")
            content = doc.get("content", "")
            labels = doc.get("labels", [])

            # Create snippet (first 200 chars)
            snippet = content[:200] + "..." if len(content) > 200 else content

            citations.append(
                DraftCitation(
                    evidence_id=evidence_id,
                    snippet=snippet,
                    labels=labels
                )
            )

        return citations

    def export_draft(
        self,
        case_id: str,
        user_id: str,
        export_format: DraftExportFormat = DraftExportFormat.DOCX
    ) -> Tuple[BytesIO, str, str]:
        """
        Export draft as DOCX or PDF file

        Process:
        1. Validate case access
        2. Generate draft preview using RAG + GPT-4o
        3. Convert to requested format (DOCX or PDF)

        Args:
            case_id: Case ID
            user_id: User ID requesting export
            export_format: Output format (docx or pdf)

        Returns:
            Tuple of (file_bytes, filename, content_type)

        Raises:
            NotFoundError: Case not found
            PermissionError: User does not have access to case
            ValidationError: Export format not supported or missing dependencies
        """
        # 1. Validate case access
        case = self.case_repo.get_by_id(case_id)
        if not case:
            raise NotFoundError("Case")

        if not self.member_repo.has_access(case_id, user_id):
            raise PermissionError("You do not have access to this case")

        # 2. Generate draft preview
        request = DraftPreviewRequest()  # Use default sections
        draft_response = self.generate_draft_preview(case_id, request, user_id)

        # 3. Convert to requested format
        if export_format == DraftExportFormat.DOCX:
            return self._generate_docx(case, draft_response)
        elif export_format == DraftExportFormat.PDF:
            return self._generate_pdf(case, draft_response)
        else:
            raise ValidationError(f"Unsupported export format: {export_format}")

    def _generate_docx(
        self,
        case,
        draft_response: DraftPreviewResponse
    ) -> Tuple[BytesIO, str, str]:
        """
        Generate DOCX file from draft response

        Args:
            case: Case object
            draft_response: Generated draft preview

        Returns:
            Tuple of (file_bytes, filename, content_type)
        """
        if not DOCX_AVAILABLE:
            raise ValidationError(
                "DOCX export is not available. "
                "Please install python-docx: pip install python-docx"
            )

        # Create document
        doc = Document()

        # Title
        title = doc.add_heading("Ïù¥Ìòº ÏÜåÏÜ° Ï§ÄÎπÑÏÑúÎ©¥ (Ï¥àÏïà)", level=0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER

        # Case info
        doc.add_paragraph()
        case_info = doc.add_paragraph()
        case_info.add_run(f"ÏÇ¨Í±¥Î™Ö: {case.title}").bold = True
        doc.add_paragraph(f"ÏÉùÏÑ±ÏùºÏãú: {draft_response.generated_at.strftime('%Y-%m-%d %H:%M:%S')}")

        # Draft content
        doc.add_heading("Î≥∏Î¨∏", level=1)
        for paragraph_text in draft_response.draft_text.split("\n\n"):
            if paragraph_text.strip():
                doc.add_paragraph(paragraph_text.strip())

        # Citations
        if draft_response.citations:
            doc.add_heading("Ïù∏Ïö© Ï¶ùÍ±∞", level=1)
            for i, citation in enumerate(draft_response.citations, 1):
                p = doc.add_paragraph()
                p.add_run(f"[Ï¶ùÍ±∞ {i}] ").bold = True
                p.add_run(f"(ID: {citation.evidence_id})")
                doc.add_paragraph(f"  - Î∂ÑÎ•ò: {', '.join(citation.labels) if citation.labels else 'N/A'}")
                doc.add_paragraph(f"  - ÎÇ¥Ïö©: {citation.snippet}")

        # Disclaimer
        doc.add_paragraph()
        disclaimer = doc.add_paragraph()
        disclaimer.add_run(
            "‚ö†Ô∏è Î≥∏ Î¨∏ÏÑúÎäî AIÍ∞Ä ÏÉùÏÑ±Ìïú Ï¥àÏïàÏù¥Î©∞, "
            "Î≥ÄÌò∏ÏÇ¨Ïùò Í≤ÄÌÜ† Î∞è ÏàòÏ†ïÏù¥ ÌïÑÏàòÏûÖÎãàÎã§."
        ).italic = True

        # Save to BytesIO
        file_buffer = BytesIO()
        doc.save(file_buffer)
        file_buffer.seek(0)

        # Generate filename
        safe_title = case.title.replace(" ", "_")[:30]
        filename = f"draft_{safe_title}_{draft_response.generated_at.strftime('%Y%m%d')}.docx"
        content_type = "application/vnd.openxmlformats-officedocument.wordprocessingml.document"

        return file_buffer, filename, content_type

    def _generate_pdf(
        self,
        case,
        draft_response: DraftPreviewResponse
    ) -> Tuple[BytesIO, str, str]:
        """
        Generate PDF file from draft response with Korean font support

        Features:
        - A4 layout for legal documents
        - Korean font support (Noto Sans KR or system fallback)
        - Legal document template structure
        - Citations section

        Args:
            case: Case object
            draft_response: Generated draft preview

        Returns:
            Tuple of (file_bytes, filename, content_type)
        """
        try:
            from reportlab.lib.pagesizes import A4
            from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
            from reportlab.platypus import (
                SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
            )
            from reportlab.lib.units import inch, mm
            from reportlab.lib import colors
            from reportlab.pdfbase import pdfmetrics
            from reportlab.pdfbase.ttfonts import TTFont
            from reportlab.lib.enums import TA_CENTER, TA_JUSTIFY
            import os

            # Register Korean font
            korean_font_registered = self._register_korean_font(pdfmetrics, TTFont)
            font_name = "NotoSansKR" if korean_font_registered else "Helvetica"

            file_buffer = BytesIO()

            # A4 with proper margins for legal documents
            doc = SimpleDocTemplate(
                file_buffer,
                pagesize=A4,
                leftMargin=25 * mm,
                rightMargin=25 * mm,
                topMargin=25 * mm,
                bottomMargin=25 * mm
            )

            # Create custom styles with Korean font
            styles = getSampleStyleSheet()

            # Title style
            title_style = ParagraphStyle(
                'KoreanTitle',
                parent=styles['Title'],
                fontName=font_name,
                fontSize=18,
                alignment=TA_CENTER,
                spaceAfter=20
            )

            # Heading style
            heading_style = ParagraphStyle(
                'KoreanHeading',
                parent=styles['Heading2'],
                fontName=font_name,
                fontSize=14,
                spaceBefore=15,
                spaceAfter=10
            )

            # Normal text style
            normal_style = ParagraphStyle(
                'KoreanNormal',
                parent=styles['Normal'],
                fontName=font_name,
                fontSize=11,
                leading=16,
                alignment=TA_JUSTIFY,
                spaceAfter=8
            )

            # Citation style
            citation_style = ParagraphStyle(
                'Citation',
                parent=styles['Normal'],
                fontName=font_name,
                fontSize=10,
                leading=14,
                leftIndent=10,
                spaceAfter=6
            )

            # Disclaimer style
            disclaimer_style = ParagraphStyle(
                'Disclaimer',
                parent=styles['Normal'],
                fontName=font_name,
                fontSize=9,
                textColor=colors.grey,
                alignment=TA_CENTER,
                spaceBefore=20
            )

            story = []

            # === Document Header ===
            story.append(Paragraph("Ïù¥Ìòº ÏÜåÏÜ° Ï§ÄÎπÑÏÑúÎ©¥", title_style))
            story.append(Paragraph("(Ï¥à Ïïà)", ParagraphStyle(
                'Subtitle',
                parent=normal_style,
                alignment=TA_CENTER,
                fontSize=12,
                spaceAfter=30
            )))

            # === Case Information Table ===
            case_data = [
                ["ÏÇ¨ Í±¥ Î™Ö", case.title],
                ["ÏÉùÏÑ±ÏùºÏãú", draft_response.generated_at.strftime('%YÎÖÑ %mÏõî %dÏùº %H:%M')],
            ]
            case_table = Table(case_data, colWidths=[80, 350])
            case_table.setStyle(TableStyle([
                ('FONTNAME', (0, 0), (-1, -1), font_name),
                ('FONTSIZE', (0, 0), (-1, -1), 11),
                ('ALIGN', (0, 0), (0, -1), 'RIGHT'),
                ('ALIGN', (1, 0), (1, -1), 'LEFT'),
                ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
                ('BOTTOMPADDING', (0, 0), (-1, -1), 8),
                ('TOPPADDING', (0, 0), (-1, -1), 8),
            ]))
            story.append(case_table)
            story.append(Spacer(1, 0.4 * inch))

            # === Main Content ===
            story.append(Paragraph("Î≥∏ Î¨∏", heading_style))

            # Split content by paragraphs and add to story
            for paragraph_text in draft_response.draft_text.split("\n\n"):
                cleaned_text = paragraph_text.strip()
                if cleaned_text:
                    # Escape XML special characters
                    cleaned_text = (
                        cleaned_text
                        .replace("&", "&amp;")
                        .replace("<", "&lt;")
                        .replace(">", "&gt;")
                    )
                    story.append(Paragraph(cleaned_text, normal_style))

            # === Citations Section ===
            if draft_response.citations:
                story.append(Spacer(1, 0.3 * inch))
                story.append(Paragraph("Ïù∏Ïö© Ï¶ùÍ±∞", heading_style))

                for i, citation in enumerate(draft_response.citations, 1):
                    # Citation header
                    labels_str = ", ".join(citation.labels) if citation.labels else "N/A"
                    citation_header = f"<b>[Ï¶ùÍ±∞ {i}]</b> (ID: {citation.evidence_id})"
                    story.append(Paragraph(citation_header, citation_style))

                    # Citation details
                    story.append(Paragraph(f"Î∂ÑÎ•ò: {labels_str}", citation_style))

                    # Citation snippet (escape special characters)
                    snippet = (
                        citation.snippet
                        .replace("&", "&amp;")
                        .replace("<", "&lt;")
                        .replace(">", "&gt;")
                    )
                    story.append(Paragraph(f"ÎÇ¥Ïö©: {snippet}", citation_style))
                    story.append(Spacer(1, 0.1 * inch))

            # === Disclaimer ===
            story.append(Spacer(1, 0.5 * inch))
            story.append(Paragraph(
                "‚ö† Î≥∏ Î¨∏ÏÑúÎäî AIÍ∞Ä ÏÉùÏÑ±Ìïú Ï¥àÏïàÏù¥Î©∞, Î≥ÄÌò∏ÏÇ¨Ïùò Í≤ÄÌÜ† Î∞è ÏàòÏ†ïÏù¥ ÌïÑÏàòÏûÖÎãàÎã§.",
                disclaimer_style
            ))

            # Build PDF
            doc.build(story)
            file_buffer.seek(0)

            safe_title = case.title.replace(" ", "_")[:30]
            filename = f"draft_{safe_title}_{draft_response.generated_at.strftime('%Y%m%d')}.pdf"
            content_type = "application/pdf"

            return file_buffer, filename, content_type

        except ImportError:
            raise ValidationError(
                "PDF export is not available. "
                "Please install reportlab: pip install reportlab. "
                "Alternatively, use DOCX format."
            )

    def _register_korean_font(self, pdfmetrics, TTFont) -> bool:
        """
        Register Korean font for PDF generation

        Tries to find and register a Korean font in this order:
        1. Noto Sans KR (bundled or system)
        2. macOS system fonts (AppleGothic, AppleSDGothicNeo)
        3. Linux system fonts (NanumGothic)
        4. Windows system fonts (Malgun Gothic)

        Args:
            pdfmetrics: reportlab pdfmetrics module
            TTFont: reportlab TTFont class

        Returns:
            bool: True if Korean font was registered, False otherwise
        """
        import os

        # Font search paths
        font_candidates = [
            # Bundled font (if exists in project)
            os.path.join(os.path.dirname(__file__), "..", "fonts", "NotoSansKR-Regular.ttf"),
            # macOS system fonts
            "/System/Library/Fonts/AppleSDGothicNeo.ttc",
            "/System/Library/Fonts/Supplemental/AppleGothic.ttf",
            "/Library/Fonts/NotoSansKR-Regular.ttf",
            # Linux system fonts
            "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
            # Windows system fonts
            "C:/Windows/Fonts/malgun.ttf",
            "C:/Windows/Fonts/NotoSansKR-Regular.ttf",
        ]

        for font_path in font_candidates:
            if os.path.exists(font_path):
                try:
                    pdfmetrics.registerFont(TTFont("NotoSansKR", font_path))
                    return True
                except Exception:
                    continue

        # No Korean font found - will use default font
        return False
